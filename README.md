# 思路与心得：
    在本次目标检测任务中，我主要参考了YOLOv1目标检测模型。在该任务中，我体验了从数据预处理，定义数据集，建立模型，定义损失函数，结果预测一系列过程，对深度学习有了更深入的了解。在实践过程中，我也遇到了一系列的问题，比如：在进行数据预处理时，因为bbox的y坐标运算写错，导致后面训练出来的模型算出来一堆负数。在这之后，我也养成了每写一个小模块都进行验证的习惯。不过，验证还是比较粗糙的，在大多数情况下，基本还是秉承着“只要不报错，能跑就算胜利”的准则。

    第一次训练跑了大概三四个小时，但模型训练出的效果特别差。当设置conf_thresh=0.1时（即置信度小于0.1时就抛弃预测框），几乎预测不出任何物体。既然发现了问题，接下来就是要解决问题。但说实话，根本不知道问题出在哪里。一开始的想法是先调一下学习率，优化器啥的，但都没有起到作用。这就有点恐怖了，一整个项目流程，数据编码解码，数据集定义，定义损失函数，任何一个环节出问题都会导致训练失败，代码千百行，一行行查过去也不一定能发现问题。。。于是，我开始一块一块地重写代码，每写一块都用一个较小的训练集跑几轮训练模型进行验证，最后发现是损失函数中写掩码的时候，把一处应该置为1的地方写成0了，导致模型往奇怪的方向进行收敛。。。

    修改完损失函数后，为了验证模型的正确性，我又用一个很小的训练集进行训练，观察是否能达到过拟合效果，并据此调整学习率等参数。

    本次目标检测任务使我了解了目标检测任务的基本流程，学习了YOLO检测模型的基本思路，熟练掌握了使用pytorch代码进行数据处理，网络定义，矩阵运算的方法，增进了我学习《深度学习》的兴趣。

    同时，在实践过程中，我也发现了yolov1训练模型存在的一点问题：
    在进行yolov1数据编码时，如果一个网格中存在多个物体，只会有一个被保留，导致数据丢失。因此，yolov1网络并不适合预测框较多的任务。

下面是一点训练的小心得：

    在华为云进行训练时可以把数据转移到./cache中，减少和OBS桶的交互，否则读取图片会很慢。
    在云端进行网络训练，在计算loss时，必须使用train_loss += loss.item()，若没有加.item()，占用的内存会一直增加，导致最后notebook直接停止运行，得重新开始训练，浪费大量时间。（本地跑好像没这个问题）
    注意自己的磁盘空间大小，有一次训练了三个小时，保存模型的时候因为云端磁盘空间不够炸炉了。。。
    可以先把每张图片对应的bbox全都整合到txt中，节省调试时间。一开始写项目时是把每张图片对应的bbox放到内存中，每次大约整合5分钟，如果在调试程序时遇到：CUDA out of memory时就得重启，重新整合一次，浪费大量时间，也不方便检查代码。
